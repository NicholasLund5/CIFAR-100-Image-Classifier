{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image classification project using the CIFAR-100 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set\n",
    "* For this project I will be using the CIFAR-100 Dataset\n",
    "* 60,000 images in total - 100 classes, 600 images per class,  10,000 test images and 50,000 training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean and std for CIFAR-100\n",
    "mean = (0.5071, 0.4865, 0.4409)\n",
    "std = (0.2673, 0.2564, 0.2762)\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "train_data = datasets.CIFAR100(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform_train,\n",
    "    target_transform=None\n",
    ")\n",
    "\n",
    "test_data = datasets.CIFAR100(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform_test,\n",
    "    target_transform=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnormalize_img(img, mean, std):\n",
    "        \"\"\"Unnormalize a tensor image.\"\"\"\n",
    "        mean = torch.tensor(mean).view(1, 1, -1)\n",
    "        std = torch.tensor(std).view(1, 1, -1)\n",
    "        return img * std + mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_idx = train_data.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting some examples of the data in gray scale\n",
    "torch.manual_seed(0)\n",
    "fig = plt.figure(figsize=(9,9))\n",
    "rows, cols = 4, 4\n",
    "\n",
    "for i in range(1, rows*cols+1):\n",
    "    rand_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
    "    img, label = train_data[rand_idx]\n",
    "    img = unnormalize_img(img.permute(1, 2, 0), mean, std)\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "    plt.title(class_names[label])\n",
    "    plt.axis(False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the DataLoader\n",
    "* Convert the data into a python iterable, and batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "BATCH_SIZE = 32\n",
    "train_dataloader = DataLoader(dataset=train_data,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_data,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataloader), len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example \n",
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
    "\n",
    "rand_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
    "img, label = train_features_batch[rand_idx], train_labels_batch[rand_idx]\n",
    "img = img.permute(1, 2, 0)\n",
    "plt.imshow(img)\n",
    "plt.title(class_names[label])\n",
    "plt.axis(False)\n",
    "print(f\"Image size: {img.shape}\")\n",
    "print(f\"Label: {label}, label size {label.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom training and test step functions for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               scheduler: torch.optim.lr_scheduler._LRScheduler, \n",
    "               accuracy_fn,\n",
    "               device: torch.device = device):\n",
    "    \"\"\"Performs a training with model traing to learn on data_loader\"\"\"\n",
    "    train_loss , train_acc = 0, 0 \n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        y_pred = model(X)\n",
    "\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss \n",
    "        train_acc += accuracy_fn(y_true=y,\n",
    "                                 y_pred=y_pred.argmax(dim=1)) # from logits -> prediction labels\n",
    "        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "    \n",
    "    scheduler.step()\n",
    "    # average out train loss over all the train data\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train acc: {train_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model: torch.nn.Module,\n",
    "              data_loader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy_fn,\n",
    "              device: torch.device = device):\n",
    "    \"\"\"Performs a testing with model traing to learn on data_loader\"\"\"\n",
    "\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            test_pred = model(X)\n",
    "\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            test_acc += accuracy_fn(y_true=y, \n",
    "                                    y_pred=test_pred.argmax(dim=1))\n",
    "\n",
    "        # Calculate the test loss\n",
    "        test_loss /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "        print(f\"Test loss: {test_loss:.4f} | Test acc {test_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqueezeExcitationBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Linear(channels, channels // reduction)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(channels // reduction, channels)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, channels, _, _ = x.size()\n",
    "        # Global average pooling\n",
    "        y = self.global_avg_pool(x).view(batch_size, channels)\n",
    "        # Fully connected layers with reduction\n",
    "        y = self.fc1(y)\n",
    "        y = self.relu(y)\n",
    "        y = self.fc2(y)\n",
    "        y = self.sigmoid(y).view(batch_size, channels, 1, 1)\n",
    "        # Scale the input features\n",
    "        return x * y\n",
    "\n",
    "class ResidualSEBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, reduction=16):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.se = SqueezeExcitationBlock(out_channels, reduction)\n",
    "\n",
    "        # Shortcut connection\n",
    "        self.shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False) \\\n",
    "                        if in_channels != out_channels or stride != 1 else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.shortcut(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.se(x)  # Apply SE block\n",
    "        return nn.ReLU()(x + shortcut)\n",
    "\n",
    "class CIFAR100Model(nn.Module):\n",
    "    def __init__(self, input_shape: int, width_multiplier: int, num_classes: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Stem stage for initial feature extraction\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Stage 1\n",
    "        self.stage1 = self._make_stage(16, 16 * width_multiplier, num_blocks=2, stride=1)\n",
    "        \n",
    "        # Stage 2\n",
    "        self.stage2 = self._make_stage(16 * width_multiplier, 32 * width_multiplier, num_blocks=2, stride=2)\n",
    "        \n",
    "        # Stage 3\n",
    "        self.stage3 = self._make_stage(32 * width_multiplier, 64 * width_multiplier, num_blocks=2, stride=2)\n",
    "        \n",
    "        # Global pooling and classifier\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.fc = nn.Linear(64 * width_multiplier, num_classes)\n",
    "\n",
    "    def _make_stage(self, in_channels, out_channels, num_blocks, stride):\n",
    "        layers = []\n",
    "        for i in range(num_blocks):\n",
    "            layers.append(\n",
    "                ResidualSEBlock(\n",
    "                    in_channels=in_channels if i == 0 else out_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    stride=stride if i == 0 else 1\n",
    "                )\n",
    "            )\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.global_pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x) \n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "model = CIFAR100Model(input_shape=3, \n",
    "                      width_multiplier=10,\n",
    "                      num_classes=len(class_names)).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating what number of in_features needed for our classifier layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "rand_image_tensor_resized = F.interpolate(rand_image_tensor.unsqueeze(0), size=(32, 32), mode='bilinear')\n",
    "\n",
    "rand_image_tensor_rgb = rand_image_tensor_resized.repeat(1, 3, 1, 1) \n",
    "\n",
    "output = model(rand_image_tensor_rgb.to(device))\n",
    "print(output.shape) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up a loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates accuracy between truth labels and predictions.\n",
    "    \"\"\"\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_train_time(start: float,\n",
    "                     end: float,\n",
    "                     device: torch.device = None):\n",
    "    \"\"\"Prints difference between start and end time.\"\"\"\n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(train_dataloader))  # Get a batch of data\n",
    "X = X.to(device)\n",
    "output = model(X)  # Pass through the model\n",
    "print(output.shape)  # Should be [batch_size, 100] for CIFAR-100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(2)\n",
    "torch.cuda.manual_seed(2)\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "train_time_model_start_2 = timer()\n",
    "epochs = 115\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    train_step(model=model,\n",
    "               data_loader=train_dataloader,\n",
    "               loss_fn=loss_fn,\n",
    "               optimizer=optimizer,\n",
    "               scheduler=scheduler,\n",
    "               accuracy_fn=accuracy_fn,\n",
    "               device=device)\n",
    "    test_step(model=model,\n",
    "               data_loader=test_dataloader,\n",
    "               loss_fn=loss_fn,\n",
    "               accuracy_fn=accuracy_fn,\n",
    "               device=device)\n",
    "\n",
    "train_time_model_end_2 = timer()\n",
    "\n",
    "total_train_time_model_2 = print_train_time(start=train_time_model_start_2,\n",
    "                                            end=train_time_model_end_2,\n",
    "                                            device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils\n",
    "torch.manual_seed(0)\n",
    "def eval_model(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               accuracy_fn,\n",
    "               device=device):\n",
    "    \"\"\"Returs a dict conatining the results of model prediciton on data_loader\"\"\"\n",
    "    loss, acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            #Make our data device agnostic\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # Make predicitoins\n",
    "            y_pred = model(X)\n",
    "\n",
    "            # Accululate the loss and acc values per batch\n",
    "            loss += loss_fn(y_pred, y)\n",
    "            acc += accuracy_fn(y_true=y,\n",
    "                               y_pred=y_pred.argmax(dim=1))\n",
    "            \n",
    "        \n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "\n",
    "    return {\"model_name\" : model.__class__.__name__, # only works when model was created with a class,\n",
    "            \"model_loss\" : loss.item(),\n",
    "            \"model_acc\" : acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CIFAR100Model(input_shape=3,  # Color channel (image.shape (1))\n",
    "                           width_multiplier=10,\n",
    "                           num_classes=len(class_names)).to(device)\n",
    "MODEL_NAME = \"CIFAR100_model.pth\"\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "model.load_state_dict(torch.load(MODEL_SAVE_PATH)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = eval_model(model=model,\n",
    "                             data_loader=test_dataloader,\n",
    "                             loss_fn=loss_fn,\n",
    "                             accuracy_fn=accuracy_fn,\n",
    "                             device=device)\n",
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model: torch.nn.Module,\n",
    "                     data: list,\n",
    "                     device: torch.device = device):\n",
    "    pred_probs = []\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for sample in data:\n",
    "            # prepare sample, add batch dimention and pass to target device\n",
    "            sample = torch.unsqueeze(sample, dim=0).to(device)\n",
    "\n",
    "            # forward pass\n",
    "            pred_logit = model(sample)\n",
    "\n",
    "            # get pred prob (logit -> prediction probability)\n",
    "            pred_prob = torch.softmax(pred_logit.squeeze(), dim=0)\n",
    "\n",
    "            pred_probs.append(pred_prob.cpu())\n",
    "\n",
    "    return torch.stack(pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1)\n",
    "test_samples = []\n",
    "test_labels = []\n",
    "\n",
    "for sample, label in random.sample(list(test_data), k=81):\n",
    "    test_samples.append(sample)\n",
    "    test_labels.append(label)\n",
    "\n",
    "test_samples[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = unnormalize_img(test_samples[0].permute(1, 2, 0), mean, std)\n",
    "plt.imshow(sample)\n",
    "plt.title(class_names[test_labels[0]])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = make_predictions(model=model,\n",
    "                              data=test_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_classses = pred_probs.argmax(dim=1)\n",
    "pred_classses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot prediciotns\n",
    "plt.figure(figsize=(81, 81))\n",
    "nrows = 9\n",
    "ncols = 9\n",
    "for i, sample in enumerate(test_samples):\n",
    "    plt.subplot(nrows, ncols, i+1)\n",
    "\n",
    "    sample = unnormalize_img(sample.permute(1, 2, 0), mean, std)\n",
    "    plt.imshow(sample)\n",
    "\n",
    "    #predition label in text form\n",
    "    pred_label = class_names[pred_classses[i]]\n",
    "\n",
    "    # get the truth label\n",
    "    truth_label = class_names[test_labels[i]]\n",
    "\n",
    "    title_text = f\"pred: {pred_label} | truth: {truth_label}\"\n",
    "\n",
    "    if pred_label == truth_label:\n",
    "        plt.title(title_text, fontsize=30, c=\"g\")\n",
    "    else:\n",
    "        plt.title(title_text, fontsize=30, c=\"r\")\n",
    "\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_NAME = \"CIFAR100_model.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj=model.state_dict(),\n",
    "           f=MODEL_SAVE_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading it back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = CIFAR100Model(input_shape=3,  # Color channel (image.shape (1))\n",
    "                           width_multiplier=10,\n",
    "                           num_classes=len(class_names)).to(device)\n",
    "MODEL_NAME = \"CIFAR100_model_(70_percent_acc).pth\"\n",
    "MODEL_PATH = Path(\"models\")\n",
    "\n",
    "loaded_model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
